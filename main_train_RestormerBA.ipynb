{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "321b0280",
   "metadata": {},
   "outputs": [],
   "source": [
    "!nvidia-smi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "59968ec3",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "os.environ['CUDA_VISIBLE_DEVICES'] = '2'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9255de5a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f9d8d16b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import torch\n",
    "import torch.nn.functional as F\n",
    "import torchvision.transforms.functional as T\n",
    "from PIL import Image\n",
    "from torch.optim import AdamW\n",
    "from torch.optim.lr_scheduler import CosineAnnealingLR\n",
    "from torch.utils.data import DataLoader\n",
    "from tqdm import tqdm\n",
    "import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4c5d2109",
   "metadata": {},
   "outputs": [],
   "source": [
    "from model_RestormerBA import Restormer\n",
    "from utils_restormerba import parse_args, BlurDataset, rgb_to_y, psnr, ssim"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f73383e0",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_path = 'data'\n",
    "data_name = 'GOPRO' #'GOPRO' 'HIDE_dataset_restormer' 'GoPro_NU_restormer'\n",
    "save_paths = 'result'\n",
    "num_blocks = [4, 6, 6, 8]\n",
    "num_heads = [1, 2, 4, 8]\n",
    "channels = [48, 96, 192, 384]\n",
    "expansion_factor = 2.66\n",
    "num_refinement = 4\n",
    "num_iter = 1 #20000 #300000\n",
    "batch_size = [8, 5, 4, 2, 1, 1] #[16, 10, 8, 4, 2, 2]\n",
    "patch_size = [128, 160, 192, 256, 320, 384]\n",
    "lr = 0.0003 #0.0003 or 0.0001 (mod)\n",
    "milestone = [3000, 5200, 6800, 8000, 9200]\n",
    "seed = -1 #no manual seed\n",
    "model_file = None #uncomment to training model & comment below\n",
    "# model_file = 'result/GOPRO_mod3_10k_bam.pth' ##uncomment to testing model & comment above"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9ffd4f36",
   "metadata": {},
   "outputs": [],
   "source": [
    "def test_loop(net, data_loader, num_iter):\n",
    "    net.eval()\n",
    "    total_psnr, total_ssim, count = 0.0, 0.0, 0\n",
    "    with torch.no_grad():\n",
    "        test_bar = tqdm(data_loader, initial=1, dynamic_ncols=True)\n",
    "        for blur, sharp, name, h, w in test_bar:\n",
    "            blur, sharp = blur.cuda(), sharp.cuda()\n",
    "            out = torch.clamp((torch.clamp(model(blur)[:, :, :h, :w], 0, 1).mul(255)), 0, 255).byte()\n",
    "            sharp = torch.clamp(sharp[:, :, :h, :w].mul(255), 0, 255).byte()\n",
    "            y, gt = rgb_to_y(out.double()), rgb_to_y(sharp.double())\n",
    "            current_psnr, current_ssim = psnr(y, gt), ssim(y, gt)\n",
    "            total_psnr += current_psnr.item()\n",
    "            total_ssim += current_ssim.item()\n",
    "            count += 1\n",
    "            save_path = '{}/{}/{}'.format(save_paths, data_name, name[0])\n",
    "            if not os.path.exists(os.path.dirname(save_path)):\n",
    "                os.makedirs(os.path.dirname(save_path))\n",
    "            Image.fromarray(out.squeeze(dim=0).permute(1, 2, 0).contiguous().cpu().numpy()).save(save_path)\n",
    "            test_bar.set_description('Test Iter: [{}/{}] PSNR: {:.2f} SSIM: {:.3f}'\n",
    "                                     .format(num_iter, 1 if model_file else num_iter,\n",
    "                                             total_psnr / count, total_ssim / count))\n",
    "    return total_psnr / count, total_ssim / count"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "defde3b1",
   "metadata": {},
   "outputs": [],
   "source": [
    "def save_loop(net, data_loader, num_iter):\n",
    "    global best_psnr, best_ssim\n",
    "    val_psnr, val_ssim = test_loop(net, data_loader, num_iter)\n",
    "    results['PSNR'].append('{:.2f}'.format(val_psnr))\n",
    "    results['SSIM'].append('{:.3f}'.format(val_ssim))\n",
    "    # save statistics\n",
    "    data_frame = pd.DataFrame(data=results, index=range(1, (num_iter if model_file else num_iter // 1000) + 1))\n",
    "    data_frame.to_csv('{}/{}_restormerba.csv'.format(save_paths, data_name), index_label='Iter', float_format='%.3f')\n",
    "    if val_psnr > best_psnr and val_ssim > best_ssim:\n",
    "        best_psnr, best_ssim = val_psnr, val_ssim\n",
    "        with open('{}/{}.txt'.format(save_paths, data_name), 'w') as f:\n",
    "            f.write('Iter: {} PSNR:{:.2f} SSIM:{:.3f}'.format(num_iter, best_psnr, best_ssim))\n",
    "        f.close()\n",
    "        \n",
    "        #Best Epoch PSNR and SSIM\n",
    "        f= open(\"training_log_restormerba.txt\",\"a+\")\n",
    "        f.write(\"Training epoch: {}\\n\".format(num_iter))\n",
    "        f.write(\"PSNR: {}\\n\".format(best_psnr))\n",
    "        f.write(\"SSIM: {}\\n\".format(best_ssim))\n",
    "        f.close()\n",
    "        \n",
    "        torch.save(model.state_dict(), '{}/{}_restormerba.pth'.format(save_paths, data_name))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4708d2ab",
   "metadata": {},
   "outputs": [],
   "source": [
    "if __name__ == '__main__':\n",
    "    test_dataset = BlurDataset(data_path, data_name, 'test')\n",
    "    test_loader = DataLoader(test_dataset, batch_size=1, shuffle=False)\n",
    "\n",
    "    results, best_psnr, best_ssim = {'PSNR': [], 'SSIM': []}, 0.0, 0.0\n",
    "    model = Restormer(num_blocks, num_heads, channels, num_refinement, expansion_factor).cuda()\n",
    "    if model_file:\n",
    "        model.load_state_dict(torch.load(model_file))\n",
    "        save_loop(model, test_loader, 1)\n",
    "    else:\n",
    "        optimizer = AdamW(model.parameters(), lr=lr, weight_decay=1e-4)\n",
    "        lr_scheduler = CosineAnnealingLR(optimizer, T_max=num_iter, eta_min=1e-6)\n",
    "        total_loss, total_num, results['Loss'], i = 0.0, 0, [], 0\n",
    "        train_bar = tqdm(range(1, num_iter + 1), initial=1, dynamic_ncols=True)\n",
    "        for n_iter in train_bar:\n",
    "            # progressive learning\n",
    "            if n_iter == 1 or n_iter - 1 in milestone:\n",
    "                end_iter = milestone[i] if i < len(milestone) else num_iter\n",
    "                start_iter = milestone[i - 1] if i > 0 else 0\n",
    "                length = batch_size[i] * (end_iter - start_iter)\n",
    "                train_dataset = BlurDataset(data_path, data_name, 'train', patch_size[i], length)\n",
    "                train_loader = iter(DataLoader(train_dataset, batch_size[i], True))\n",
    "                i += 1\n",
    "            # train\n",
    "            model.train()\n",
    "            blur, sharp, name, h, w = next(train_loader)\n",
    "            blur, sharp = blur.cuda(), sharp.cuda()\n",
    "            out = model(blur)\n",
    "            loss = F.l1_loss(out, sharp)\n",
    "            \n",
    "            optimizer.zero_grad()\n",
    "            loss.backward()\n",
    "            \n",
    "            optimizer.step()\n",
    "            total_num += blur.size(0)\n",
    "            total_loss += loss.item() * blur.size(0)\n",
    "            train_bar.set_description('Train Iter: [{}/{}] Loss: {:.3f}'\n",
    "                                      .format(n_iter, num_iter, total_loss / total_num))\n",
    "\n",
    "            lr_scheduler.step()\n",
    "            if n_iter % 1000 == 0:\n",
    "                curr_time = time.strftime(\"%H:%M:%S\", time.localtime())\n",
    "                print(\"Current Time is :\", curr_time)\n",
    "                #log training per 1k epoch into txt file\n",
    "                f= open(\"training_log_restormer_mod3_10k_bam2.txt\",\"a+\")\n",
    "                f.write(\"Training epoch: {}\\n\".format(n_iter))\n",
    "                f.write(\"Time: {}\".format(curr_time))\n",
    "                f.write(\"\\n\\n\".format(curr_time))\n",
    "                torch.save(model.state_dict(), '{}/{}_mod3_10k_bam2.pth'.format(save_paths, data_name))\n",
    "                f.close()\n",
    "                \n",
    "            if n_iter % 10000 == 0:\n",
    "                results['Loss'].append('{:.3f}'.format(total_loss / total_num))\n",
    "                save_loop(model, test_loader, n_iter)\n",
    "                #log training per 10k epoch into txt file\n",
    "                curr_time = time.strftime(\"%H:%M:%S\", time.localtime())\n",
    "                print(\"Current Time is :\", curr_time)\n",
    "                f= open(\"training_log_restormer_mod3_10k_bam2.txt\",\"a+\")\n",
    "                f.write(\"Testing epoch: {}\\n\".format(n_iter))\n",
    "                f.write(\"Time: {}\".format(curr_time))\n",
    "                f.write(\"\\n\\n\".format(curr_time))\n",
    "                f.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0f19a9be",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "jupytext": {
   "cell_metadata_filter": "-all",
   "main_language": "python",
   "notebook_metadata_filter": "-all",
   "text_representation": {
    "extension": ".py",
    "format_name": "light"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
